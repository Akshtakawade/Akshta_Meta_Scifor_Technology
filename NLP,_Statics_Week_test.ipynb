{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXSgDpxQ4Tuw0kvUd+9LgS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Write a program of text processing\n",
        "\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "def text_processing(text):\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Split text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Count number of words\n",
        "    word_count = len(words)\n",
        "\n",
        "    # Count number of characters\n",
        "    char_count = len(text.replace(\" \", \"\"))  # Exclude spaces\n",
        "\n",
        "    # Count number of sentences\n",
        "    sentence_count = text.count('.') + text.count('!') + text.count('?')\n",
        "\n",
        "    # Find the most common words\n",
        "    word_freq = Counter(words)\n",
        "    most_common_words = word_freq.most_common(5)  # Get 5 most common words\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Total number of words: {word_count}\")\n",
        "    print(f\"Total number of characters (excluding spaces): {char_count}\")\n",
        "    print(f\"Total number of sentences: {sentence_count}\")\n",
        "    print(\"Most common words:\")\n",
        "    for word, freq in most_common_words:\n",
        "        print(f\"{word}: {freq}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample text input\n",
        "    sample_text = \"\"\"Hello world! This is a simple text processing program.\n",
        "                     It processes text to count words, characters, and sentences.\n",
        "                     This program is written in Python. Python is great for text processing.\"\"\"\n",
        "\n",
        "    text_processing(sample_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW3uqixsrEiH",
        "outputId": "8e3884b8-74cf-4dee-b0dc-a074dc7129dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words: 30\n",
            "Total number of characters (excluding spaces): 153\n",
            "Total number of sentences: 0\n",
            "Most common words:\n",
            "is: 3\n",
            "text: 3\n",
            "this: 2\n",
            "processing: 2\n",
            "program: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a program to implement NLP based upon spacy\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load the English NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text for processing\n",
        "text = \"Artificial Intelligence (AI) is transforming industries across the globe.\"\n",
        "\n",
        "# Process the text using SpaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Tokenization\n",
        "print(\"Tokens:\")\n",
        "for token in doc:\n",
        "    print(token.text)\n",
        "\n",
        "# Part-of-Speech Tagging\n",
        "print(\"\\nPart-of-Speech Tags:\")\n",
        "for token in doc:\n",
        "    print(f\"{token.text}: {token.pos_}\")\n",
        "\n",
        "# Named Entity Recognition\n",
        "print(\"\\nNamed Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text}: {ent.label_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SzEKT15rleG",
        "outputId": "40e76e3c-0563-4d5c-c4cb-37396b7f77fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:\n",
            "Artificial\n",
            "Intelligence\n",
            "(\n",
            "AI\n",
            ")\n",
            "is\n",
            "transforming\n",
            "industries\n",
            "across\n",
            "the\n",
            "globe\n",
            ".\n",
            "\n",
            "Part-of-Speech Tags:\n",
            "Artificial: PROPN\n",
            "Intelligence: PROPN\n",
            "(: PUNCT\n",
            "AI: PROPN\n",
            "): PUNCT\n",
            "is: AUX\n",
            "transforming: VERB\n",
            "industries: NOUN\n",
            "across: ADP\n",
            "the: DET\n",
            "globe: NOUN\n",
            ".: PUNCT\n",
            "\n",
            "Named Entities:\n",
            "Artificial Intelligence (AI: ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Difference between descriptive and inferential statistics. Write down atleast 10-15 differences\n",
        "\n",
        "# Descriptive Statistics\n",
        "Descriptive Summarizes and presents data.\n",
        "Works with the entire dataset (population) or a sample.\n",
        "Calculating the average score of a class of students or plotting a histogram of exam scores.\n",
        "Includes measures like mean, median, mode, standard deviation, range, and visual tools like histograms, bar charts, and pie charts.\n",
        "Describes data without predictions.\n",
        "Provides factual descriptions and summaries of data.\n",
        "Can be applied to the whole population or a sample, but does not involve sampling techniques beyond the given dataset.\n",
        "Does not directly involve probability since it deals with already observed data.\n",
        "The outcome is a summary of the data (e.g., average, percentage, or graph).\n",
        "No sampling needed; works with all data.\n",
        "\n",
        "\n",
        "\n",
        "# Inferential Statistics\n",
        "Makes predictions or generalizations about a population from a sample.\n",
        "Works with a sample to draw conclusions about a population.\n",
        "Estimating the average score of all students in a school based on the scores of a few students (sample).\n",
        "Includes hypothesis testing, confidence intervals, regression analysis, and analysis of variance (ANOVA).\n",
        "Extends beyond the data and is used to make predictions or generalizations about a population.\n",
        "Makes predictions or conclusions beyond the sample.\n",
        "Relies on sample data to make inferences about the population, often requiring sampling methods like random sampling.\n",
        "Based on probability theory, as it uses sample data to estimate population parameters with certain levels of confidence.\n",
        "The outcome is a conclusion or decision about a population parameter (e.g., whether a drug is effective based on sample testing).\n",
        "Relies on sampling techniques."
      ],
      "metadata": {
        "id": "K7e3ZyQstfMJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}